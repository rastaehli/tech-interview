========== Question 1 =================================================
Given two strings s and t, determine whether some anagram
of t is a substring of s. For example: if s = 'udacity' and t = 'ad',
then the function returns True. Your function definition should look
like: 'question1(s, t)', and return a boolean True or False.

=== Design ===
I took what seemed like a very direct and simple approach to this solution:
for each place in s that could contain an anagram of t, iterate through
the candidate value removing the letters of t that have been used.

=== Complexity ===
Complexity is a function of both len s and len t.  Call these n and m.
The main function question1 has a main loop that executes in the worst
case n times as it iterates through positions of s.  Inside this loop, the
function 'anagramFound' iterates m times as it checks for each letter in t,
but it also calls 'if s[p] in bag' and 'bag.remove(s[p])', which are both
O(m).  So the inner loop executes in the worst case m * 2m.  The overall
complexity is O(nm^2).  It is worth noting that the algorithm returns False
immediately if m > n and any optimization should consider the common range
of sizes for each input.

Space complexity is O(m) since each call of anagramFound allocates and 
frees a list of size m.  This memory management could be eliminated by
reusing a bag data structure that allowed us to keep track
which letters had been removed.


========== Question 2 =================================================
Given a string a, find the longest palindromic substring contained in a. Your
function definition should look like question2(a), and return a string.

=== Design ===
This solution uses divide and conquer: first observe that any empty
or one character string is a palindrome.  Starting with these, look 
for opportunities to extend each when they have matching characters at 
either end.  Remember the longest found so far and also keep a list of 
palindromes found that might still be extended.

=== Complexity ===
Complexity is a function of the length of a which we'll call n.  To setup
the linked list of candidate palindromes, this algorithm iterates through 
nearly all elements once to find doubles, then again to find palindromes of 
length three.  

In the worst case (all letters the same) the main loop begins
with a list of approximately 2n palindromes of length 2 and 3 and removes the 
outer four (2 that started as doubles and 2 that started as triples) each 
iteration until none are left: the number of palindromes visited in each
pass through the list is 2n + 2n-4 + 2n-8... or approximately n^2.  
Because the length of the largest palindrome grows by two characters each 
pass, it takes n/2 iterations before the algorithm terminates.  The
operations within the inner loop to test and grow/remove each palindrome
are constant time, so the complexity is 2n + n/2 * n^2, which in big-O
notation is O(n^3).

However, the average case is much better.  Suppose that the input was 
composed of common english language text and that the average case
longest palindrome was m, independent of the input text length n.  Then
the algorithm makes two passes through the full string to find the 2 and 
3 character palindromes and creates a list of perhaps n/10 palindromes found.
The size of the list shrinks rapidly with each pass as larger palindromes
are rare and the algorithm stops after m passes when no longer palindromes
are found.  The average case complexity is then approximately 2n + mn/10
or O(mn).  Since m is a constant, the complexity is O(n).

The additional space required is primarily for the linked list items, which
are small fixed size Palindrome objects.  The space complexity is O(n).


======= Question 3 =================================================
	Given an undirected graph G, find the minimum spanning tree within G. 
	A minimum spanning tree connects all vertices in a graph with the smallest
	possible total weight of edges. Your function should take in and return an
	adjacency list structured like this:

	{'A': [('B', 2)],
	 'B': [('A', 2), ('C', 5)],
	 'C': [('B', 5)]}

	Vertices are represented as unique strings. The function definition should
	be question3(G)

== Design ==
I spent too much time trying to figure out what a brute force approach would
even look like: enumerating all possible trees from all possible roots and
skipping only those that are known to be longer that the minimum found so
far.  But that approach seems very inefficient and I could not think of how
to memo-ize (remember) the trees explored so far in a way that would
eliminate recomputation.

After sketching simple examples and thinking about edge cases where a
very few nodes were closely connected to nearly all the others, it occured
to me that the minimum spanning tree could be built up from the shortest 
edges (those with lowest value).

This algorithm computes a minimum spanning tree for the input graph
by adding edges to the tree shortest edge first.  That is, the list of
all edges in the graph is sorted and the shortest edge is removed:
  - If this edge connects two nodes that are not yet part of the tree
    then the edge and its nodes are remembered as a partition to be
    connected to the rest of the tree later.
  - If this edge connects a node in a known partition to a node not yet in the
    tree, then this edge and the new node are added to this partition.
  - If this edge connects nodes in two different known partitions
    the partitions are merged and the edge added.
  - If this edge connects two nodes already visited, the edge is discarded.

This process is repeated for each edge until all nodes from the graph are 
in the tree and all partitions have been merged.  This assumes that the input
graph is connected and that it does not matter which direction edges are 
traversed.

Each partition maintains a dictionary of its nodes so it is efficient to 
test whether a given node is contained in the partition.

Because this algorithm adds each node exactly
once with an edge connecting it to the rest, a tree is formed.  Because
the tree is constructed shortest edge first, we know it is a minimum
spanning tree.  I believe this could be proved by induction but I won't
attempt to prove it here.

=== Complexity ===
Complexity of this algorithm depends on the number of nodes n and the
number of edges e.  In the initial sort of the edges uses the default 
Python sort function for lists, which is O(e(log e)).  The main loop adds
one or two nodes to the tree each loop so in the worst case it executes
n times.  Inside the main loop, the search for the next edge that grows
the tree consists of:
  - popping from the edgeQueue which is O(1)
  - getUnvisitedNodes which is O(1)
  - sometimes calling partitionsConnected, which iterates through the list
    of known partitions, checking their dictionaries for the associated nodes.
    The python dictionary lookup is O(1) and the number of partitions begins
    at 1 and can never be bigger than the number of n/2 since each
    partition has at least 2 nodes in it.  In the worst case this is O(n).
And also in the main loop, the growing of the tree consists of:
  - adding a partition which is O(1), or
  - finding a partition to add a node and edge, which is O(n), or
  - merging two partitions, which O(n + e) in the worst case

Putting this together, I get:
  e(log e) + n( 1 or n or n+e )

When n is large, this is O(n^2), but if e is much larger than n then the n*e
term would be more significant.

The additional space complexity is significant, because the algorithm creates
copies of the nodes while constructing the tree and each partition contains a 
potentially large dictionary for node lookup by value.  A simple implemenation
of this lookup might create a dictionary with size O(n) which would require
O(n^2) additional space, but the python implementation probably already grows
with the number of objects stored, and the total nodes stored in our partions
is always less than or equal to n, which means the additional space is 
only O(n).

